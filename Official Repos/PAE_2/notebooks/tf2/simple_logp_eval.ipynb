{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAE logp sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D-Fe5G8m1FTC",
    "outputId": "8f21ee4e-6ad4-4fe2-a7a5-0bad6eae0cde"
   },
   "outputs": [],
   "source": [
    "\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "import sys\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams.update({'font.family' : 'lmodern', 'font.size': 16,                                                                                                                                                    \n",
    "                     'axes.labelsize': 16, 'legend.fontsize': 12, \n",
    "                     'xtick.labelsize': 16, 'ytick.labelsize': 16, 'axes.titlesize': 16,\n",
    "                     'axes.linewidth': 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AEYmOsH1FTI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_hub as hub\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tf.__version__\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0 0.10.0 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__, tfp.__version__, hub.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained modules and evaluating logp in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxW5NtaPZLTi"
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"../../\" \n",
    "PARAMS_PATH = os.path.join(PROJECT_PATH,'params')\n",
    "\n",
    "param_file  = 'params_mnist_-1_10_vae10_AE_test_full_sigma'\n",
    "params      = pickle.load(open(os.path.join(PARAMS_PATH,param_file+'.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this with your own data load function\n",
    "load_func                                          = partial(load_funcs[params['data_set']])\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_func(params['data_dir'],flatten=True)\n",
    "######\n",
    "\n",
    "x_train = x_train/256.-0.5\n",
    "x_test  = x_test/256.-0.5\n",
    "x_valid = x_valid/256.-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cscratch1/sd/vboehm/RNF/modules/mnist/class-1/latent_size10/net_type_vae10/loss_AE/test_full_sigma\n"
     ]
    }
   ],
   "source": [
    "print(params['module_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models and parameter file are in the shared folder, you will have to pass their directory here\n",
    "generator_path   = os.path.join(params['module_dir'],'decoder')\n",
    "encoder_path     = os.path.join(params['module_dir'],'encoder')\n",
    "nvp_path         = os.path.join(params['module_dir'],'hybrid8_nepoch220')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(decoder,sigma):\n",
    "    \n",
    "    #sigma = np.repeat(np.expand_dims(sigma,0), params['batch_size'], 0) \n",
    "    def likelihood(z):\n",
    "        mean  = decoder({'z':z})['x']\n",
    "        \n",
    "        LL = tfd.MultivariateNormalDiag(loc=mean,scale_diag=sigma)\n",
    "        return tfd.Independent(LL)\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "def get_prior(latent_size):\n",
    "    return tfd.MultivariateNormalDiag(tf.zeros(latent_size), scale_identity_multiplier=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_fill        = tf.Variable(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),trainable=False)\n",
    "\n",
    "sigma         = params['full_sigma']\n",
    "sigma         = tf.cast(sigma,tf.float32)\n",
    "\n",
    "encoder       = hub.KerasLayer(encoder_path,trainable=False, signature_outputs_as_dict=True)\n",
    "decoder       = hub.KerasLayer(generator_path, trainable=False, signature_outputs_as_dict=True)\n",
    "nvp_funcs     = hub.KerasLayer(nvp_path, trainable=False, signature_outputs_as_dict=True)\n",
    "\n",
    "likelihood    = get_likelihood(decoder,np.repeat(np.expand_dims(sigma,0),16,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "yvTEYw44O_5q",
    "outputId": "898dcdf7-f38f-4dae-a3aa-4f32a487f0ae"
   },
   "outputs": [],
   "source": [
    "def get_encoded(x):\n",
    "    return encoder({'x':x})['z']\n",
    "\n",
    "def get_decoded(z):\n",
    "    return decoder({'z':z})['x']\n",
    "\n",
    "def likelihood_eval(z,x,likelihood):\n",
    "    likelihood    = likelihood(z).log_prob(x)\n",
    "    return likelihood\n",
    "\n",
    "def prior_eval(z,nvp_funcs=nvp_funcs):\n",
    "    prior         = nvp_funcs({'z_sample':z,'sample_size':1, 'u_sample':np.zeros((1,params['latent_size']))})['log_prob']\n",
    "    return prior\n",
    "\n",
    "def posterior_eval(z,x,likelihood, nvp_funcs):\n",
    "    likelihood   = likelihood_eval(z,x,likelihood)\n",
    "    prior        = get_prior(params['latent_size'])\n",
    "    prior        = prior_eval(z, nvp_funcs)\n",
    "    logprob      = likelihood+prior\n",
    "    return logprob\n",
    "\n",
    "\n",
    "class LogP():\n",
    "    def __init__(self,x):\n",
    "        self.x = x\n",
    "        self.z_fill = tf.Variable(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),trainable=False)\n",
    "    \n",
    "    def logp_grad(self,z):\n",
    "\n",
    "        self.z_fill.assign(z)\n",
    "        z_  = tf.convert_to_tensor(self.z_fill)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z_)\n",
    "            log_p         = posterior_eval(z_,self.x,likelihood,nvp_funcs)\n",
    "        grad = tape.gradient(log_p, [z_])\n",
    "        #print(grad)\n",
    "        return log_p, grad[0]\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def logp(self,z):\n",
    "\n",
    "        logp, grads = self.logp_grad(z)\n",
    "\n",
    "        def grad(up,variables=None):\n",
    "            #print(up.shape)\n",
    "            grad_ = tf.expand_dims(up,-1)*grads\n",
    "\n",
    "            return grad_, [None for ii in range(len(variables))] \n",
    "\n",
    "        return logp, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer keras_layer_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# need to feed it a batch of 16, hence the repeat\n",
    "x     = np.repeat(x_test[0:1], 16, axis=0)\n",
    "z_ini = get_encoded(x)\n",
    "#logp evaluation\n",
    "y = LP.logp(z_ini)[0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LambdaNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
