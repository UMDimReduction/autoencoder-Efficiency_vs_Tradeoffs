{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Distributin detection on different OoD and with different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D-Fe5G8m1FTC",
    "outputId": "8f21ee4e-6ad4-4fe2-a7a5-0bad6eae0cde"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "# #To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "import sys\n",
    "import pickle\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.family' : 'lmodern', 'font.size': 16,                                                                                                                                                    \n",
    "                     'axes.labelsize': 16, 'legend.fontsize': 12, \n",
    "                     'xtick.labelsize': 16, 'ytick.labelsize': 16, 'axes.titlesize': 16,\n",
    "                     'axes.linewidth': 1.5}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AEYmOsH1FTI"
   },
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow_hub as hub\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GI5FLHJsZLTV"
   },
   "outputs": [],
   "source": [
    "from pae.model_tf2 import get_prior, get_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9oAjWb9ZLTc"
   },
   "outputs": [],
   "source": [
    "import pae.create_datasets as crd\n",
    "import pae.load_data as ld\n",
    "load_funcs=dict(mnist=ld.load_mnist, fmnist=ld.load_fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxW5NtaPZLTi"
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"../../\" \n",
    "PARAMS_PATH = os.path.join(PROJECT_PATH,'params')\n",
    "\n",
    "param_file = 'params_fmnist_-1_64_infoGAN_AE_v2rot_full_sigma'\n",
    "params      = pickle.load(open(os.path.join(PARAMS_PATH,param_file+'.pkl'),'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_func                                          = partial(load_funcs[params['data_set']])\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_func(params['data_dir'],flatten=False)\n",
    "\n",
    "if np.all(x_test)==None:\n",
    "    x_test=x_valid\n",
    "\n",
    "x_train    = x_train/255.-0.5\n",
    "x_test     = x_test/255.-0.5\n",
    "x_valid    = x_valid/255.-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(dataset,flip='no'):\n",
    "    if dataset=='omniglot':\n",
    "        import tensorflow_datasets as tfds\n",
    "        from skimage.transform import resize\n",
    "        omni= tfds.load('omniglot')\n",
    "        glot = tfds.as_numpy(omni)\n",
    "        samples=[]\n",
    "        for sample in glot['test']:\n",
    "            s = resize(sample['image'],(28,28))\n",
    "            samples.append(-(s-0.5))\n",
    "        samples=np.asarray(samples)\n",
    "        samples = np.mean(samples[0:10000],axis=-1)\n",
    "        x_valid_ood=np.expand_dims(samples,-1)\n",
    "    else:\n",
    "        load_func                                         = partial(load_funcs[dataset])\n",
    "        x_train_ood, y_train, x_valid_ood, y_valid, x_test_ood, y_test = load_func(params['data_dir'],flatten=False)\n",
    "\n",
    "        if np.all(x_test)==None:\n",
    "            x_test_ood=x_valid_ood\n",
    "\n",
    "        if  flip=='horizontal':\n",
    "            x_test_ood    = np.asarray([np.fliplr(x) for x in x_test_ood/255.-0.5])\n",
    "        elif flip=='vertical':\n",
    "            x_test_ood    = np.asarray([np.flipud(x) for x in x_test_ood/255.-0.5])\n",
    "        else:\n",
    "            x_test_ood    = x_test_ood/255.-0.5\n",
    "\n",
    "    for ii in range(2):\n",
    "        plt.imshow(np.squeeze(x_test_ood[ii]),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return x_test_ood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reproduce results choose either 'mnist', 'fmnist', or 'omniglot'. To flip use keyword 'horizontal' or 'vertical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_valid_ood=get_outliers('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_path   = os.path.join(params['module_dir'],'decoder')\n",
    "encoder_path     = os.path.join(params['module_dir'],'encoder')\n",
    "nvp_path         = os.path.join(params['module_dir'],'hybrid1_nepoch100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(decoder,sigma):\n",
    "  \n",
    "    def likelihood(z):\n",
    "        mean = decoder({'z':z},as_dict=True)['x']\n",
    "        return tfd.Independent(tfd.MultivariateNormalDiag(loc=mean,scale_diag=sigma))\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "yvTEYw44O_5q",
    "outputId": "898dcdf7-f38f-4dae-a3aa-4f32a487f0ae"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data          = tf.placeholder(shape=params['full_size'],dtype=tf.float32)\n",
    "MAP_ini       = tf.placeholder_with_default(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),shape=(params['batch_size'],params['latent_size']))\n",
    "lr            = tf.placeholder_with_default(1e-4,shape=[])\n",
    "\n",
    "encoder       = hub.Module(encoder_path, trainable=False)\n",
    "decoder       = hub.Module(generator_path, trainable=False)\n",
    "nvp_funcs     = hub.Module(nvp_path, trainable=False)\n",
    "sigma         = tf.placeholder_with_default(params['full_sigma'],shape=[28,28,1])\n",
    "sigma         = tf.cast(sigma,tf.float32)\n",
    "optimizer     = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "likelihood       = get_likelihood(decoder,sigma)\n",
    "prior            = get_prior(params['latent_size'])\n",
    "posterior        = get_posterior(encoder)\n",
    "approx_posterior = posterior(data)\n",
    "\n",
    "encoded         = approx_posterior.mean()\n",
    "\n",
    "# here, the MAP lives in z-space\n",
    "MAP              = tf.Variable(MAP_ini)\n",
    "MAP_reset        = tf.stop_gradient(MAP.assign(MAP_ini))\n",
    "\n",
    "#evaluate log prob of z'\n",
    "MAP_prior        = nvp_funcs({'z_sample':MAP,'sample_size':1, 'u_sample':np.zeros((1,params['latent_size']))},as_dict=True)['log_prob']\n",
    "#this is the Gaussian probability in u space (used to isolate log det J)\n",
    "bwd_pass         = nvp_funcs({'z_sample':MAP,'sample_size':1, 'u_sample':np.zeros((1,params['latent_size']))},as_dict=True)['bwd_pass']\n",
    "MAP_Gauss        = prior.log_prob(bwd_pass)\n",
    "# the Jacobian should be the difference\n",
    "NF_Jac           = MAP_prior - MAP_Gauss\n",
    "\n",
    "decoded          = likelihood(MAP).mean()\n",
    "MAP_likelihood   = likelihood(MAP).log_prob(data)\n",
    "\n",
    "px_tilde         = MAP_likelihood+MAP_prior\n",
    "\n",
    "recon            = -tf.reduce_mean(tf.square(decoded-data),axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Soh1tnGH1FTW"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Measured Sigma, log_post with single sample, Log Likelihood at Encoded and Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tts2_qqiZLUR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior\n",
      "nats: 37.266376\n",
      "bits per dim: 0.06857655173693726\n",
      "AUROC: 0.997\n",
      "likelihood\n",
      "nats: -2525.697\n",
      "bits per dim: -4.647717560820833\n",
      "AUROC: 0.855\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import simps\n",
    "\n",
    "metrics = ['prior','likelihood']\n",
    "labels  = ['NF prior','recon_error']\n",
    "objs    = [MAP_prior,MAP_likelihood]\n",
    "\n",
    "\n",
    "AUROC=[]\n",
    "false_positive=[]\n",
    "sig = np.maximum(params['full_sigma'],10)\n",
    "for jj in range(len(metrics)):\n",
    "    print(metrics[jj])\n",
    "    objective=[]\n",
    "    for ii in range(len(x_valid)//params['batch_size']):\n",
    "        data_sample = x_valid[ii*params['batch_size']:(ii+1)*params['batch_size']]\n",
    "        MAP_init = sess.run(encoded,feed_dict={data:data_sample,sigma:sig})\n",
    "        sess.run(MAP_reset,feed_dict={MAP_ini:MAP_init,sigma:sig})\n",
    "        objective+=[sess.run(objs[jj],feed_dict={data:data_sample,MAP_ini:MAP_init,sigma:sig})]\n",
    "    delta = len(x_valid)%params['batch_size']\n",
    "    data_sample = np.concatenate((x_valid[(ii+1)*params['batch_size']:len(x_valid)],x_valid[0:params['batch_size']-delta]))\n",
    "    MAP_init = sess.run(encoded,feed_dict={data:data_sample,sigma:sig})\n",
    "    sess.run(MAP_reset,feed_dict={MAP_ini:MAP_init,sigma:sig})\n",
    "    objective+=[sess.run(objs[jj],feed_dict={data:data_sample,MAP_ini:MAP_init,sigma:sig})]\n",
    "    objective = np.asarray(objective).flatten()[0:len(x_valid)]\n",
    "\n",
    "\n",
    "    objective_ood=[]\n",
    "    for ii in range(len(x_valid_ood)//params['batch_size']):\n",
    "        data_sample = x_valid_ood[ii*params['batch_size']:(ii+1)*params['batch_size']]\n",
    "        MAP_init = sess.run(encoded,feed_dict={data:data_sample,sigma:sig})\n",
    "        sess.run(MAP_reset,feed_dict={MAP_ini:MAP_init,sigma:sig})\n",
    "        objective_ood+=[sess.run(objs[jj],feed_dict={data:data_sample,MAP_ini:MAP_init,sigma:sig})]\n",
    "    delta = len(x_valid)%params['batch_size']\n",
    "    data_sample = np.concatenate((x_valid_ood[(ii+1)*params['batch_size']:len(x_valid_ood)],x_valid_ood[0:params['batch_size']-delta]))\n",
    "    MAP_init = sess.run(encoded,feed_dict={data:data_sample,sigma:sig})\n",
    "    sess.run(MAP_reset,feed_dict={MAP_ini:MAP_init,sigma:sig})\n",
    "    objective_ood+=[sess.run(objs[jj],feed_dict={data:data_sample,MAP_ini:MAP_init,sigma:sig})]\n",
    "    objective_ood = np.asarray(objective_ood).flatten()[0:len(x_valid)]\n",
    "\n",
    "    objective = np.asarray(objective)\n",
    "    objective_ood = np.asarray(objective_ood)\n",
    "    objs_ = np.sort(objective)\n",
    "    objs_ood_ = np.sort(objective_ood)\n",
    "    print('nats:', np.mean(objs_))\n",
    "    print('bits per dim:', np.mean(objs_)/np.log(2)/(28*28))\n",
    "    false_pos=[]\n",
    "    true_pos=[]\n",
    "    for ii in range(10000):\n",
    "        val = objs_[ii]\n",
    "        true_pos.append(len(np.where(objs_>=val)[0])/len(objs_))\n",
    "        false_pos.append(len(np.where(objs_ood_>=val)[0])/len(objs_))\n",
    "    false_pos = np.asarray(false_pos,dtype=np.float64)\n",
    "    AUROC+=[1-np.sum(false_pos)*1./np.float(len(objs_))]\n",
    "    print('AUROC:',np.round(AUROC[-1],3))\n",
    "false_positive.append(false_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LambdaNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
