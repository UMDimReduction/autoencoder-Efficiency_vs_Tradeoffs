{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAE logp sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D-Fe5G8m1FTC",
    "outputId": "8f21ee4e-6ad4-4fe2-a7a5-0bad6eae0cde"
   },
   "outputs": [],
   "source": [
    "\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.disable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.family' : 'lmodern', 'font.size': 16,                                                                                                                                                    \n",
    "                     'axes.labelsize': 16, 'legend.fontsize': 12, \n",
    "                     'xtick.labelsize': 16, 'ytick.labelsize': 16, 'axes.titlesize': 16,\n",
    "                     'axes.linewidth': 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AEYmOsH1FTI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_hub as hub\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tf.__version__\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0 0.10.0 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__, tfp.__version__, hub.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained modules and evaluating logp in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxW5NtaPZLTi"
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"../../\" \n",
    "PARAMS_PATH = '/global/cscratch1/sd/vboehm/PAE_samples/FMNIST/latent_dim32/VAE/modules'\n",
    "\n",
    "param_file  = 'params_fmnist_-1_32_infoGAN_VAE_v2_full_sigma_beta100_C15'\n",
    "params      = pickle.load(open(os.path.join(PARAMS_PATH,param_file+'.pkl'),'rb'))\n",
    "params['module_dir']='/global/cscratch1/sd/vboehm/PAE_samples/FMNIST/latent_dim32/VAE/modules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_path   = os.path.join(params['module_dir'],'decoder')\n",
    "encoder_path     = os.path.join(params['module_dir'],'encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(latent_size):\n",
    "    return tfd.MultivariateNormalDiag(tf.zeros(latent_size), scale_identity_multiplier=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(decoder,sigma):\n",
    "    sigma = tf.reshape(sigma,(params['batch_size'],-1))\n",
    "    def likelihood(z):\n",
    "        mean  = decoder({'z':z})['x']\n",
    "        mean  = tf.reshape(mean,(params['batch_size'],-1))\n",
    "        \n",
    "        LL = tfd.MultivariateNormalDiag(loc=mean,scale_diag=sigma)\n",
    "        return tfd.Independent(LL)\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_fill        = tf.Variable(tf.zeros((params['batch_size'],params['latent_size']),tf.float32),trainable=False)\n",
    "\n",
    "sigma         = params['full_sigma']\n",
    "sigma         = sigma.astype(np.float32)\n",
    "\n",
    "encoder       = hub.KerasLayer(encoder_path,trainable=False, signature_outputs_as_dict=True)\n",
    "decoder       = hub.KerasLayer(generator_path, trainable=False, signature_outputs_as_dict=True)\n",
    "\n",
    "\n",
    "likelihood    = get_likelihood(decoder,np.repeat(np.expand_dims(sigma,0),params['batch_size'],axis=0))\n",
    "       \n",
    "prior         = get_prior(params['latent_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "yvTEYw44O_5q",
    "outputId": "898dcdf7-f38f-4dae-a3aa-4f32a487f0ae"
   },
   "outputs": [],
   "source": [
    "def get_encoded(x):\n",
    "    mu, sigma        = tf.split(encoder({'x':x})['z'], 2, axis=-1)\n",
    "    return mu\n",
    "\n",
    "def get_decoded(z):\n",
    "    return decoder({'z':z})['x']\n",
    "\n",
    "def likelihood_eval(z,x,likelihood):\n",
    "    likelihood_   = likelihood(z).log_prob(x)\n",
    "    return likelihood_\n",
    "\n",
    "def prior_eval(z, prior):\n",
    "    prior_         = prior.log_prob(z)\n",
    "    return prior_\n",
    "\n",
    "def posterior_eval(z,x,likelihood, prior):\n",
    "    x            = tf.reshape(x,(params['batch_size'],-1))\n",
    "    likelihood_  = likelihood_eval(z,x,likelihood)\n",
    "    prior_       = prior_eval(z, prior)\n",
    "    logprob      = likelihood_+prior_\n",
    "    return logprob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LambdaNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
