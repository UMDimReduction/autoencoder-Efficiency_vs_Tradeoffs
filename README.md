# Autoencoder: Efficiency vs Tradeoffs

![Author](https://img.shields.io/badge/author-aaneloy-blue) 
![Author](https://img.shields.io/badge/turgeonmaxime-red)
[![MIT](https://img.shields.io/badge/license-MIT-5eba00.svg)](https://github.com/UMDimReduction/autoencoder-Efficiency_vs_Tradeoffs/blob/main/LICENSE.txt)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/UMDimReduction/autoencoder-Efficiency_vs_Tradeoffs)

## Update Logs:
The reproduction is still **ongoing**. Please refer the following logs for current and future updates:
1. Individual implimentation using official and partial references as mentioned in the paper is updated.
2. Single-Click result implimentation is ongoing.
3. Other autoencoder models will be added in the future.

## Overview
This repository introduces the paper **"A Comprehensive Study of Auto-Encoders for
Anomaly Detection: Efficiency and Trade-Offs"** by **[Asif Ahmed Neloy](https://aaneloy.ca/)** and **[Dr. Max Turgeon](https://www.maxturgeon.ca/)**.


The following autonencoders are reproduced in this repository:
* Denoising Auto-Encoder **(DAE)**
* Sparse Auto-Encoder **(SAE)**
* Contractive Auto-Encoder **(CAE)**
* Variational Auto-Encoder **(VAE)**
* Conditional Variational Auto-Encoder **(CVAE)**
* **beta-VAE**
* Adversarial Variational Auto-Encoder **(adVAE)**
* Importance Weighted Auto-Encoder **(IWAE)**
* Probabilistic Auto-Encoder **(PAE)**
* Robust Deep Auto-Encoders **(RDA)**
* Vector Quantised-Variational Auto-Encoder **(VQ-VAE)**


## Reproducibility

The reproducibility process is divided into two process- 
1. Reproduce individual results using the [Official repos](https://github.com/UMDimReduction/autoencoder-Efficiency_vs_Tradeoffs/tree/main/Official%20Repos) or [Particial reference repos](https://github.com/UMDimReduction/autoencoder-Efficiency_vs_Tradeoffs/tree/main/Partial%20References) 
2. Reproduce all results using the modified models.


### Install Requirements

The ``requirements.txt`` file contains python packages for reproducing all models. **There is no individual requirements.txt file**. 

#### Prerequisite:
* Anaconda
* Python 3.7.11
* Windows 10/11 (*also can be reproduced using any linux machine. However, the package requirements needs to be adjusted*)
* GPUs (***PyTorch** and **TensorFlow** are created using gpu models*)

####Installation steps:
* create new env: ``conda create -name autoencoder python=3.7 -y``
* activate env: ``conda activate autoencoder``
* open the directory and install the **``requirements.txt``**: ``pip install -r requirements.txt``


### Individual Results

#### 1. DAE
``
cd 
``

#### 2. SAE

#### 3. CAE


#### 4. VAE

#### 5. CVAE

#### 6. beta-VAE

#### 7. adVAE

#### 8. IWAE

#### 9. PAE


#### 10. RDA


#### 11. VQ-VAE



### All Results





## License
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)